# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V3Wl426ZyTW8M4kDUIqDlfmuwX2do3Q_
"""

from textblob import TextBlob
import nltk
from nltk.tokenize import word_tokenize
from collections import Counter
from nltk.corpus import stopwords
import string

import matplotlib.pyplot as plt
import pandas as pd
from google.colab import files

pip install googletrans==4.0.0-rc1

from googletrans import Translator

# Initialize the translator
translator = Translator()
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('averaged_perceptron_tagger')

# Upload the Excel file
uploaded = files.upload()

import io
df = pd.read_excel(io.BytesIO(uploaded['with classification.xlsx']))
# Convert the dataframe to CSV
df.to_csv('output.csv', index=False)
df.columns[153]

sentence = "היי בוקר טוב היה לי אתמול ערב לא פשוט ואני לא יודעת אם הותקפתי או לא אוקיי אני קצת מפחדת שהזיכרון יעלם אלך לרופאת משפחה שלי יותר מאוחר. "



"""***Translations***"""

# Initialize the Google Translate client
translation = translator.translate(sentence, src='he', dest='en')
sentence_english = translation.text
sentence_english

"""***Tokenization***

1.   CC: Coordinating conjunction
2. CD: Cardinal number
3. DT: Determiner
4. EX: Existential there
5. FW: Foreign word
6. IN: Preposition or subordinating conjunction
7. JJ: Adjective
8. JJR: Adjective, comparative
9. JJS: Adjective, superlative
10. LS: List item marker
11. MD: Modal
12. NN: Noun, singular or mass
13. NNS: Noun, plural
14. NNP: Proper noun, singular
15. NNPS: Proper noun, plural
16. PDT: Predeterminer
17. POS: Possessive ending
18. PRP: Personal pronoun
19. PRP$: Possessive pronoun
20. RB: Adverb
21. RBR: Adverb, comparative
22. RBS: Adverb, superlative
23. RP: Particle
24. SYM: Symbol
25. TO: to
26. UH: Interjection
27. VB: Verb, base form
28. VBD: Verb, past tense
29. VBG: Verb, gerund or present participle
30. VBN: Verb, past participle
31. VBP: Verb, non-3rd person singular present
32. VBZ: Verb, 3rd person singular present
33. WDT: Wh-determiner
34. WP: Wh-pronoun
35. WP$: Possessive wh-pronoun
36. WRB: Wh-adverb
"""

tokens_english = nltk.word_tokenize(sentence_english)
print(tokens_english)

tagged_tokens_english = nltk.pos_tag(tokens_english)
tagged_tokens_english

# Count the appearance of each word
word_counts = Counter(tokens_english)

# Print the word counts
for word, count in word_counts.items():
    print(word, ':', count)

# Remove stopwords and punctuation
stop_words = set(stopwords.words('english'))
punctuation = set(string.punctuation)
stop_words

# Convert all words to lowercase
words_english = [word.lower() for word in tokens_english]

filtered_words = [word for word in words_english if word not in stop_words and word not in punctuation]
print("Filtered words:", filtered_words)

# Count the appearance of each word
word_counts = Counter(filtered_words)

# Plot the histogram of token frequencies
plt.figure(figsize=(12, 6))
plt.bar(word_counts.keys(), word_counts.values())
plt.xlabel('Words')
plt.ylabel('Frequency')
plt.title('Token Frequency Histogram')
plt.xticks(rotation=45)
plt.show()